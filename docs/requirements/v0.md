# LLM Screen Overlay Application Requirements

## Overview
An Electron desktop application that captures screen content and provides real-time AI-powered advice through an overlay. Initially focused on gaming scenarios but designed for extensibility to other use cases.

## Phase 1: MVP - Real-time Advice System

### Core Features
1. **Window Capture**: User-selectable window capture with continuous streaming
2. **Gemini Integration**: Real-time API streaming with 10-15 minute context window
3. **Overlay Display**: Fixed position (top-right), semi-transparent advice display
4. **Configuration**: API key and custom system instructions

### Technical Architecture

```
Core Modules:
├── Capture/
│   ├── WindowSelector    // UI for selecting target window
│   ├── ScreenRecorder    // Continuous frame capture
│   └── FrameProcessor    // Optimize frames for LLM transmission
│
├── LLM/
│   ├── GeminiClient      // Real-time streaming API integration
│   ├── PromptManager     // System instruction handling
│   └── ContextBuffer     // Maintain 10-15 min sliding window
│
├── Overlay/
│   ├── OverlayWindow     // Electron transparent window
│   ├── AdviceRenderer    // Display LLM responses
│   └── ErrorDisplay      // Show connection/API errors
│
└── Config/
    ├── SettingsStore     // API keys, instructions persistence
    └── ConfigUI          // Settings interface
```

### Testable Milestones

#### Milestone 1: Screen Capture Foundation (Week 1)
**Goal**: Capture and display selected window frames

**Deliverables**:
- Window selector UI that lists available windows
- Continuous frame capture at configurable FPS (default: 1-2 fps for low CPU)
- Local frame display to verify capture quality

**Test Criteria**:
```typescript
// Test: Can capture specific window
// Test: CPU usage < 5% during capture
// Test: Frame quality sufficient for LLM analysis
```

#### Milestone 2: Overlay System (Week 2)
**Goal**: Display floating overlay window

**Deliverables**:
- Transparent Electron window (always-on-top)
- Fixed position (top-right) with configurable offset
- Basic text rendering with semi-transparent background
- Hotkey to toggle visibility (e.g., Ctrl+Shift+O)

**Test Criteria**:
```typescript
// Test: Overlay stays above game window
// Test: Text remains readable over various backgrounds
// Test: Toggle hotkey works during gameplay
```

#### Milestone 3: Gemini Integration (Week 3-4)
**Goal**: Connect to Gemini real-time API

**Deliverables**:
- Gemini API client with streaming support
- Frame-to-base64 conversion for API transmission
- Context buffer maintaining 10-15 minutes of history
- Error handling with user-friendly messages

**Test Criteria**:
```typescript
// Test: Successfully stream frames to Gemini
// Test: Receive coherent responses within 2-3 seconds
// Test: Handle API errors gracefully
// Test: Context window rotation works correctly
```

#### Milestone 4: Configuration System (Week 5)
**Goal**: User-configurable settings

**Deliverables**:
- Settings UI for API key input
- System instruction text area (multiline)
- Save/load configuration to local storage
- Example prompts for different scenarios

**Test Criteria**:
```typescript
// Test: API key securely stored
// Test: System instructions affect LLM behavior
// Test: Settings persist between app restarts
```

#### Milestone 5: MVP Integration (Week 6)
**Goal**: Complete working system

**Deliverables**:
- Full pipeline: capture → process → send → display
- Performance optimization (frame skipping, compression)
- Basic usage documentation
- Example gaming scenario tested (Ravenswatch)

**Test Criteria**:
```typescript
// Test: End-to-end advice generation during gameplay
// Test: Advice relevance and timeliness
// Test: System stability over 30-minute sessions
```

## Phase 2: Post-Game Analysis (Future)

### Additional Features
- Local screenshot storage with timestamps
- Session recording and replay
- Batch analysis of game sessions
- Performance metrics and improvement tracking

## Phase 3: Multi-LLM Support (Future)

### Extensibility
- Plugin architecture for different LLM providers
- Provider-specific optimizations
- Fallback chain for reliability

## Non-Functional Requirements

### Performance
- CPU usage: < 10% during active streaming
- Memory: < 500MB baseline
- Latency: < 3 seconds from capture to advice display

### Security
- API keys encrypted in local storage
- No external data transmission except to configured LLM
- Optional local-only mode for sensitive contexts

### Extensibility Design Decisions
- System instructions as plain text enables any use case
- Modular architecture allows feature toggling
- Clear domain boundaries for easy enhancement

## Example System Instructions

### Gaming Coach
```
You are a gaming coach observing gameplay. Provide concise, actionable advice:
- Focus on immediate tactical decisions
- Highlight missed opportunities
- Suggest skill improvements
- Keep advice under 50 words
```

### Coding Assistant
```
You are observing a developer's screen. Provide helpful suggestions:
- Identify potential bugs or issues
- Suggest better implementations
- Remind about best practices
- Only speak when you see clear improvements
```

### Presentation Coach
```
You are a presentation coach. While observing slides:
- Point out unclear messaging
- Suggest visual improvements
- Note speaking opportunities
- Keep feedback constructive and brief
```